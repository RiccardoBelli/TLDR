{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data/emails.txt'\n",
    "with open(path, 'rb') as f:\n",
    "    text = f.read().decode('utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_tags(text_with_html):\n",
    "    # Define a regular expression pattern to match HTML tags\n",
    "    html_tag_pattern = re.compile('<.*?>')\n",
    "\n",
    "    # Use the `sub` method to replace all matched HTML tags with an empty string\n",
    "    text_without_html = re.sub(html_tag_pattern, '', text_with_html)\n",
    "\n",
    "    return text_without_html\n",
    "\n",
    "text = remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "def cleanup(dirty_text):\n",
    "\n",
    "    # Define a regular expression pattern to match nested square brackets\n",
    "    square_brackets_pattern = regex.compile(r'\\[(?:[^[\\]]*|(?R))*\\]')\n",
    "    dirty_text = regex.sub(square_brackets_pattern, '', dirty_text)\n",
    "\n",
    "    # Define a regular expression pattern to match text inside square brackets\n",
    "    square_brackets_pattern = re.compile(r'\\[.*?\\]')\n",
    "    dirty_text = re.sub(square_brackets_pattern, '', dirty_text)\n",
    "\n",
    "    # Weird character\n",
    "    dirty_text = dirty_text.replace(\"=E2=80=99\", \"`\")\n",
    "\n",
    "    # Define a regular expression pattern to match '=E2=80=' followed by a number\n",
    "    e2_80_sequence_pattern = re.compile(r'=E2=80=\\d+')\n",
    "    dirty_text = re.sub(e2_80_sequence_pattern, '', dirty_text)\n",
    "\n",
    "    # Define a regular expression pattern to match sequences starting with '=' and ending with a number\n",
    "    equals_sequence_pattern = re.compile(r'=([A-F0-9]{2}=)+\\d+')\n",
    "    dirty_text = re.sub(equals_sequence_pattern, '', dirty_text)\n",
    "\n",
    "    # Define a regular expression pattern to match '=' followed by any non-letter characters\n",
    "    equals_non_letters_pattern = re.compile('=([^a-zA-Z]+)')\n",
    "    dirty_text = re.sub(equals_non_letters_pattern, '', dirty_text)\n",
    "\n",
    "    clean_text = dirty_text.replace(\"=E2\", \"`\")\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def remove_minute_read(text):\n",
    "    # Define a regular expression pattern to match the sequence\n",
    "    minute_read_pattern = re.compile(r'\\(?\\d*\\s*MINUTE\\s*READ\\)?', re.IGNORECASE)\n",
    "\n",
    "    # Use the `sub` method to replace all matched sequences with an empty string\n",
    "    clean_text = re.sub(minute_read_pattern, '', text)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "text = cleanup(text)\n",
    "text = remove_minute_read(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments = [\n",
    "    \"BIG TECH & STARTUPS\",\n",
    "    \"SCIENCE & FUTURISTIC TECHNOLOGY\",\n",
    "    \"PROGRAMMING, DESIGN & DATA SCIENCE\",\n",
    "    \"MISCELLANEOUS\"\n",
    "]\n",
    "\n",
    "def extract_sections(text, start_section, end_section):\n",
    "    # Define the regular expression pattern to match the desired sections\n",
    "    pattern = re.compile(r'(?i){}(.*?)(?={})'.format(re.escape(start_section), re.escape(end_section)), re.MULTILINE | re.DOTALL)\n",
    "    sections = re.findall(pattern, text)\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIG TECH & STARTUPS: 213 sections extracted\n",
      "SCIENCE & FUTURISTIC TECHNOLOGY: 212 sections extracted\n",
      "PROGRAMMING, DESIGN & DATA SCIENCE: 240 sections extracted\n"
     ]
    }
   ],
   "source": [
    "text_by_argument = {}\n",
    "\n",
    "# Iterate through the sections_to_extract list using indices\n",
    "for i in range(len(arguments) - 1):\n",
    "    argument = arguments[i]\n",
    "    next_argument = arguments[i + 1]\n",
    "\n",
    "    text_by_argument[argument] = extract_sections(text, argument, next_argument)\n",
    "\n",
    "for section, content in text_by_argument.items():\n",
    "    print(f\"{section}: {len(content)} sections extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BIG NEWS FROM MICROSOFT CTO ANDREAS BRAUN \n",
      "\n",
      "\n",
      "\n",
      "Microsoft CTO Andreas Braun announced that GPT-4 will be released as\n",
      "early as next week. The new model will be multimodal and will have\n",
      "video capabilities. The announcement was made during the 'AI in Focus\n",
      "- Digital Kickoff' hybrid event held on March 9 whereMicrosoft\n",
      "Germany employees presented LLMs like the GPT series.GOOGLE DUSTS OFF THE FAILED GOOGLE+ PLAYBOOK TO FIGHT CHATGPT \n",
      "\n",
      "\n",
      "\n",
      "Google was threatened by Facebook's rise to success in 2011. This\n",
      "prompted thecompany to issue a decree to its employees to build\n",
      "social features intoeverything, with their bonuses tied to Google's\n",
      "social success. The decree resulted in ham-fisted social integrations\n",
      "across Google that users despised, such as YouTube comments being tied\n",
      "to Google+ and the real name policy. Just like with the company's\n",
      "social panic, its current ChatGPT panic may see employees' ratings and\n",
      "reviews for promotions influenced by their ability to integrate\n",
      "artificial intelligence into their work.\n"
     ]
    }
   ],
   "source": [
    "def print_first_10_sections(sections):\n",
    "    for i, section in enumerate(sections[:10], start=1):\n",
    "        print(section)\n",
    "\n",
    "#print the first 10 extracted section for the BIG TECH & STARTUPS argument\n",
    "#print_first_10_sections(text_by_argument[arguments[0]])\n",
    "print(text_by_argument[arguments[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_url(url, filepath='temp'):\n",
    "  import requests\n",
    "  r = requests.get(url)\n",
    "  with open(filepath, 'wb') as f:\n",
    "      f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_companies(companies):\n",
    "    # Convert companies in string \n",
    "    for i,company in enumerate(companies):\n",
    "        companies[i] = company.get_text().lower()\n",
    "\n",
    "    # Append Bigh Techs in parentheses and cleaning\n",
    "    # Alphabet (Google) --> Alphabet, Google\n",
    "    for i,company in enumerate(companies):\n",
    "        if('(' in company):\n",
    "            companies.append(company[company.find('(')+1:company.find(')')])\n",
    "            companies[i] = company[0:company.find('(')-1]\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies():\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    url = 'https://companiesmarketcap.com/tech/largest-tech-companies-by-market-cap/'\n",
    "\n",
    "    download_from_url(url)\n",
    "    html_text = open('temp', 'r', encoding=\"utf-8\").read()\n",
    "\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    # Get the first 10 companies in tags\n",
    "    companies = soup.findAll('div', {'class':'company-name'})[0:10]\n",
    "\n",
    "    return clean_companies(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da mappare con arguments (?)\n",
    "science_kw = [    \n",
    "    'science', 'mathematics', 'physics', 'biology', 'scientific studies', \n",
    "    'astronomy', 'chemistry', 'botany', 'genetics', 'zoology', \n",
    "    'physiology', 'earth', 'geology', 'meteo','ecology', 'research']\n",
    "\n",
    "programming_kw = [\n",
    "    'programming', 'framework', 'repo', 'repository', 'tool', 'api', \n",
    "    'html', 'css', 'js', 'javascript', 'java', 'pyhton', 'c++', 'c#', \n",
    "    'design', 'data','data science', 'git', 'sql', 'db', 'database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lucar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(text):\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # print(\"Numero di tokens:\", len(tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La section è Big Tech? True\n",
      "La section è Science? False\n",
      "La section è Programming? False\n"
     ]
    }
   ],
   "source": [
    "def contains_keywords(section, keywords):\n",
    "    for token in tokenize(section):\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in token.lower():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "print(\"La section è Big Tech?\", contains_keywords(text_by_argument[arguments[0]][0], get_companies()))\n",
    "print(\"La section è Science?\", contains_keywords(text_by_argument[arguments[0]][0], science_kw))\n",
    "print(\"La section è Programming?\", contains_keywords(text_by_argument[arguments[0]][0], science_kw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIG TECH & STARTUPS\n"
     ]
    }
   ],
   "source": [
    "def get_argument(section):\n",
    "    if(contains_keywords(section,get_companies())):\n",
    "        return arguments[0]\n",
    "    elif(contains_keywords(section,science_kw)):\n",
    "        return arguments[1]\n",
    "    elif(contains_keywords(section,programming_kw)):\n",
    "        return argument[2]\n",
    "    return arguments[3]\n",
    "\n",
    "print(get_argument(text_by_argument[arguments[0]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIG NEWS FROM MICROSOFT CTO ANDREAS BRAUN\n"
     ]
    }
   ],
   "source": [
    "def get_header(section):\n",
    "    header = ''\n",
    "    for token in tokenize(section):\n",
    "        if not token.isupper():\n",
    "            header = header[:len(header)-1]\n",
    "            return header\n",
    "        header += token+' '\n",
    "\n",
    "print(get_header(text_by_argument[arguments[0]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataFrame(sections):\n",
    "    import pandas as pd\n",
    "\n",
    "    col1 ='section header'\n",
    "    col2 = 'section argument'\n",
    "\n",
    "    data_set = { col1 : [], col2 : [] }\n",
    "\n",
    "    for single_section in sections:\n",
    "        data_set[col1].append(get_header(single_section))\n",
    "        data_set[col2].append(get_argument(single_section))\n",
    "   \n",
    "    df = pd.DataFrame(data_set)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section header</th>\n",
       "      <th>section argument</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIG NEWS FROM MICROSOFT CTO ANDREAS BRAUN</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ELON MUSK WASTES NO TIME CHANGING TWITTER</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ELON MUSK PLANNING VINE REBOOT AFTER TWITTER A...</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RIP GOOGLE HANGOUTS</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ELON MUSK BARS TWITTER EMPLOYEES FROM THE COMP...</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FACEBOOK PARENT META IS PREPARING TO NOTIFY EM...</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TWITTER TELLS ADVERTISERSTHAT USER GROWTH IS A...</td>\n",
       "      <td>SCIENCE &amp; FUTURISTIC TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELON MUSK HAS DISCUSSED PUTTINGALL OF TWITTER ...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>META LAYING OFF MORE THANTHOUSAND EMPLOYEES</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>READ ELON MUSK 'S FIRST EMAIL TOALL TWITTER EM...</td>\n",
       "      <td>BIG TECH &amp; STARTUPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      section header  \\\n",
       "0          BIG NEWS FROM MICROSOFT CTO ANDREAS BRAUN   \n",
       "1          ELON MUSK WASTES NO TIME CHANGING TWITTER   \n",
       "2  ELON MUSK PLANNING VINE REBOOT AFTER TWITTER A...   \n",
       "3                                RIP GOOGLE HANGOUTS   \n",
       "4  ELON MUSK BARS TWITTER EMPLOYEES FROM THE COMP...   \n",
       "5  FACEBOOK PARENT META IS PREPARING TO NOTIFY EM...   \n",
       "6  TWITTER TELLS ADVERTISERSTHAT USER GROWTH IS A...   \n",
       "7  ELON MUSK HAS DISCUSSED PUTTINGALL OF TWITTER ...   \n",
       "8        META LAYING OFF MORE THANTHOUSAND EMPLOYEES   \n",
       "9  READ ELON MUSK 'S FIRST EMAIL TOALL TWITTER EM...   \n",
       "\n",
       "                  section argument  \n",
       "0              BIG TECH & STARTUPS  \n",
       "1              BIG TECH & STARTUPS  \n",
       "2              BIG TECH & STARTUPS  \n",
       "3              BIG TECH & STARTUPS  \n",
       "4              BIG TECH & STARTUPS  \n",
       "5              BIG TECH & STARTUPS  \n",
       "6  SCIENCE & FUTURISTIC TECHNOLOGY  \n",
       "7                                O  \n",
       "8                    MISCELLANEOUS  \n",
       "9              BIG TECH & STARTUPS  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for t in text_by_argument[arguments[0]][:10]:\n",
    "    a.append(t)\n",
    "\n",
    "show_dataFrame(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
