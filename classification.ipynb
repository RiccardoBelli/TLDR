{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "target_names = [\n",
    "    \"Big Tech & Startups\",\n",
    "    \"Science & Futuristic Technology\",\n",
    "    \"Programming, Design & Data Science\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_datasets(prefix):\n",
    "    train_df = pd.read_pickle(f'data/{prefix}_training.pkl')\n",
    "    validation_df = pd.read_pickle(f'data/{prefix}_validation.pkl')\n",
    "    test_df = pd.read_pickle(f'data/{prefix}_test.pkl')\n",
    "\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "articles_train_df, articles_validation_df, articles_test_df = load_datasets(\"articles\")\n",
    "sentences_train_df, sentences_validation_df, sentences_test_df = load_datasets(\"sentences\")\n",
    "\n",
    "# Prepare the data and labels for articles\n",
    "articles_training_data = articles_train_df['text'].tolist()\n",
    "articles_training_labels = articles_train_df['category_code'].tolist()\n",
    "articles_test_data = articles_test_df['text'].tolist()\n",
    "articles_test_labels = articles_test_df['category_code'].tolist()\n",
    "articles_validation_data = articles_validation_df['text'].tolist()\n",
    "articles_validation_labels = articles_validation_df['category_code'].tolist()\n",
    "\n",
    "\n",
    "# Prepare the data and labels for sentences\n",
    "sentences_training_data = sentences_train_df['text'].tolist()\n",
    "sentences_training_labels = sentences_train_df['category_code'].tolist()\n",
    "sentences_test_data = sentences_test_df['text'].tolist()\n",
    "sentences_test_labels = sentences_test_df['category_code'].tolist()\n",
    "sentences_validation_data = sentences_validation_df['text'].tolist()\n",
    "sentences_validation_labels = sentences_validation_df['category_code'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_multinomial_nb(training_data, training_labels, test_data, test_labels):\n",
    "    vectorizer = CountVectorizer()\n",
    "    training_features = vectorizer.fit_transform(training_data)\n",
    "    test_features = vectorizer.transform(test_data)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    predictions = classifier.predict(test_features)\n",
    "\n",
    "    return classification_report(test_labels, predictions, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_logistic_regression(training_data, training_labels, test_data, test_labels):\n",
    "    vectorizer = CountVectorizer()\n",
    "    training_features = vectorizer.fit_transform(training_data)\n",
    "    test_features = vectorizer.transform(test_data)\n",
    "\n",
    "    pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression())\n",
    "    pipeline.fit(training_features, training_labels)\n",
    "    predictions = pipeline.predict(test_features)\n",
    "\n",
    "    return classification_report(test_labels, predictions, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_tfidf_logistic_regression(training_data, training_labels, test_data, test_labels):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    training_features = vectorizer.fit_transform(training_data)\n",
    "    test_features = vectorizer.transform(test_data)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(training_features, training_labels)\n",
    "    predictions = classifier.predict(test_features)\n",
    "\n",
    "    return classification_report(test_labels, predictions, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_labels(dataset):\n",
    "    words = {'train','validation','test'}\n",
    "    try:\n",
    "        for word in words:\n",
    "            dataset[word]=dataset[word].rename_column (\"category_code\", \"label\")\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "pretrained_model = \"bert-base-multilingual-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(training_df, validation_df, test_df):\n",
    "    dataset = datasets.DatasetDict({\n",
    "        \"train\":Dataset(pa.Table.from_pandas(training_df)),\n",
    "        \"validation\":Dataset(pa.Table.from_pandas(validation_df)),\n",
    "        \"test\":Dataset(pa.Table.from_pandas(test_df))})\n",
    "    rename_labels(dataset)\n",
    "    return dataset\n",
    "    \n",
    "dataset = create_dataset(articles_train_df, articles_validation_df, articles_test_df)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(pretrained_model+\"_tldr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_classifier = pipeline(\n",
    "\n",
    "    task=\"text-classification\", model=f'./{pretrained_model}_tldr',\n",
    "    tokenizer = tokenizer,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "full = True\n",
    "\n",
    "test_subset = tokenized_dataset[\"test\"]\n",
    "\n",
    "if not full:\n",
    "  N=20\n",
    "  test_subset=test_subset.shuffle(seed=77).select(range(N))\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for num in range(len(test_subset)):\n",
    "\n",
    "  if num % 10 == 0:\n",
    "    print (\"Ho classificato \"+str(num)+\" su \"+str(len(test_subset))+\" esempi\")\n",
    "\n",
    "  preds = text_classifier(test_subset[num]['text'][0:512])\n",
    "  y_pred.append(int(preds[0]['label'].split('_')[-1]))\n",
    "  y_true.append(int(test_subset[num]['label']))\n",
    "  if verbose:  \n",
    "    if int(y_true[-1]) != int(y_pred[-1]):\n",
    "      print ('classificazione: ', target_names[y_pred[-1]])\n",
    "      print ('ground truth: ', target_names[y_true[-1]])\n",
    "      print (test_subset[num]['text'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MultinomialNB for articles:\")\n",
    "print(train_and_evaluate_multinomial_nb(articles_training_data, articles_training_labels, articles_test_data, articles_test_labels))\n",
    "\n",
    "print(\"Logistic Regression for articles:\")\n",
    "print(train_and_evaluate_logistic_regression(articles_training_data, articles_training_labels, articles_test_data, articles_test_labels))\n",
    "\n",
    "print(\"TF-IDF Logistic Regression for articles:\")\n",
    "print(train_and_evaluate_tfidf_logistic_regression(articles_training_data, articles_training_labels, articles_test_data, articles_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MultinomialNB for sentences:\")\n",
    "print(train_and_evaluate_multinomial_nb(sentences_training_data, sentences_training_labels, sentences_test_data, sentences_test_labels))\n",
    "\n",
    "print(\"Logistic Regression for sentences:\")\n",
    "print(train_and_evaluate_logistic_regression(sentences_training_data, sentences_training_labels, sentences_test_data, sentences_test_labels))\n",
    "\n",
    "print(\"TF-IDF Logistic Regression for sentences:\")\n",
    "print(train_and_evaluate_tfidf_logistic_regression(sentences_training_data, sentences_training_labels, sentences_test_data, sentences_test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
